{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 100\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mxnet import image\n",
    "style_img = image.imread('resources/style_6.jpg')\n",
    "content_img = image.imread('resources/content_1.jpg')\n",
    "\n",
    "from mxnet import nd\n",
    "\n",
    "rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def preprocess(img, image_shape):\n",
    "    img = image.imresize(img, *image_shape)\n",
    "    img = (img.astype('float32')/255 - rgb_mean) / rgb_std\n",
    "    return img.transpose((2,0,1)).expand_dims(axis=0)\n",
    "\n",
    "def postprocess(img):\n",
    "    img = img[0].as_in_context(rgb_std.context)\n",
    "    return (img.transpose((1,2,0))*rgb_std + rgb_mean).clip(0,1)\n",
    "\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "pretrained_net = models.vgg19(pretrained=True)\n",
    "# print(pretrained_net)\n",
    "\n",
    "# style_layers = [0,5,10,19,28]\n",
    "# content_layers = [21]\n",
    "style_layers = [10,28]\n",
    "content_layers = [0,5,19,21]\n",
    "pooling_layers = [4,9,18,27,36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1] [1]\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import nn\n",
    "\n",
    "def get_net(pretrained_net, content_layers, style_layers):\n",
    "    net = nn.HybridSequential()\n",
    "    for i in range(max(content_layers+style_layers)+1):\n",
    "        if i in pooling_layers:\n",
    "            net.add(nn.MaxPool2D(pool_size=2, strides=2))\n",
    "        else:\n",
    "            net.add(pretrained_net.features[i])\n",
    "    return net\n",
    "\n",
    "net = get_net(pretrained_net, content_layers, style_layers)\n",
    "net.hybridize()\n",
    "\n",
    "def extract_features(x, content_layers, style_layers):\n",
    "    contents = []\n",
    "    styles = []\n",
    "    for i in range(len(net)):\n",
    "        x = net[i](x)\n",
    "        if i in style_layers:\n",
    "            styles.append(x)\n",
    "        if i in content_layers:\n",
    "            contents.append(x)\n",
    "    return contents, styles\n",
    "\n",
    "\n",
    "def content_loss(yhat, y):\n",
    "    return (yhat-y).square().mean()\n",
    "#     return nd.sum((yhat-y).square()) * 0.5\n",
    "\n",
    "\n",
    "def gram(x):\n",
    "    c = x.shape[1]\n",
    "    n = int(x.size / x.shape[1])\n",
    "    y = x.reshape((c, n))\n",
    "    return nd.dot(y, y.T) / n\n",
    "\n",
    "\n",
    "def style_loss(yhat, gram_y):\n",
    "    c = yhat.shape[1]\n",
    "    n = yhat.size / yhat.shape[1]\n",
    "    return (gram(yhat) - gram_y).square().mean()/ 4\n",
    "\n",
    "def tv_loss(yhat):\n",
    "    return 0.5*((yhat[:,:,1:,:] - yhat[:,:,:-1,:]).abs().mean() +\n",
    "                (yhat[:,:,:,1:] - yhat[:,:,:,:-1]).abs().mean())\n",
    "\n",
    "channels = [net[l].weight.shape[0] for l in style_layers]\n",
    "style_weights = [1 for l in style_layers]\n",
    "# style_weights = [1e5 /n**2 for n in channels]\n",
    "# content_weights = [1]\n",
    "content_weights = [1 for l in content_layers]\n",
    "tv_weight = 0\n",
    "\n",
    "print(style_weights, content_weights)\n",
    "\n",
    "def sum_loss(loss, preds, truths, weights):\n",
    "    return nd.add_n(*[w*loss(yhat, y) for w, yhat, y in zip(\n",
    "        weights, preds, truths)])\n",
    "\n",
    "def get_contents(image_shape):\n",
    "    content_x = preprocess(content_img, image_shape).copyto(ctx)\n",
    "    content_y, _ = extract_features(content_x, content_layers, style_layers)\n",
    "    return content_x, content_y\n",
    "\n",
    "def get_styles(image_shape, color_matching=None):\n",
    "    style_x = preprocess(style_img, image_shape)\n",
    "    if color_matching:\n",
    "        style_x = color_matching(style_x, content_x.copyto(style_x.context))\n",
    "    style_x = style_x.copyto(ctx)\n",
    "    content_x.copyto(ctx)\n",
    "    _, style_y = extract_features(style_x, content_layers, style_layers)\n",
    "    style_y = [gram(y) for y in style_y]\n",
    "    return style_x, style_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "\n",
    "def covariance(x, u=0):\n",
    "    x = x - u\n",
    "    c = x.shape[0]\n",
    "    n = int(x.size / x.shape[0])\n",
    "    y = x.reshape((c, -1))\n",
    "    return nd.dot(y, y.T) / n\n",
    "\n",
    "def cholesky_color_matching(style_img, content_img):\n",
    "    \n",
    "    content_img = content_img[0]\n",
    "    style_img = style_img[0]\n",
    "\n",
    "    content_u = nd.mean(content_img, axis=(1,2)).reshape((-1, 1, 1))\n",
    "    style_u = nd.mean(style_img, axis=(1,2)).reshape((-1, 1, 1))  \n",
    "    \n",
    "    content_covariance = covariance(content_img, content_u)\n",
    "    style_covariance = covariance(style_img, style_u)\n",
    "    \n",
    "    L_c = nd.linalg_potrf(content_covariance)\n",
    "    L_s = nd.linalg_potrf(style_covariance)\n",
    "    L_s_inv = nd.array(np.mat(L_s.asnumpy()).I) \n",
    "    \n",
    "    A = nd.dot(L_c, L_s_inv)\n",
    "    b = content_u - nd.dot(A, style_u)\n",
    "    \n",
    "    return (nd.dot(A, style_img) + b).expand_dims(axis=0)\n",
    "\n",
    "def analogies_color_matching(style_img, content_img):\n",
    "    \n",
    "    content_img = content_img[0]\n",
    "    style_img = style_img[0]\n",
    "\n",
    "    content_u = nd.mean(content_img, axis=(1,2)).reshape((-1, 1, 1))\n",
    "    style_u = nd.mean(style_img, axis=(1,2)).reshape((-1, 1, 1))  \n",
    "    \n",
    "    content_covariance = covariance(content_img, content_u)\n",
    "    style_covariance = covariance(style_img, style_u)\n",
    "    \n",
    "    L_c = sqrtm(content_covariance.asnumpy())\n",
    "    L_s = sqrtm(style_covariance.asnumpy())\n",
    "    L_c = nd.array(L_c)\n",
    "    L_s_inv = nd.array(np.mat(L_s).I) \n",
    "    \n",
    "    A = nd.dot(L_c, L_s_inv)\n",
    "    b = content_u - nd.dot(A, style_u)\n",
    "    \n",
    "    return (nd.dot(A, style_img) + b).expand_dims(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0, content 0.000, style 1474.541, time 0.8 sec\n",
      "epoch  40, content 97.134, style nan, time 17.3 sec\n",
      "epoch  80, content 97.134, style nan, time 17.1 sec\n",
      "epoch 120, content 97.134, style nan, time 17.7 sec\n",
      "epoch 160, content 97.134, style nan, time 16.5 sec\n",
      "epoch 200, content 97.134, style nan, time 16.4 sec\n",
      "epoch 240, content 97.134, style nan, time 18.5 sec\n",
      "epoch 280, content 97.134, style nan, time 18.4 sec\n",
      "change lr to  0.05\n",
      "epoch 320, content 97.134, style nan, time 18.4 sec\n",
      "epoch 360, content 97.134, style nan, time 18.3 sec\n",
      "epoch 400, content 97.134, style nan, time 18.4 sec\n",
      "epoch 440, content 97.134, style nan, time 17.3 sec\n",
      "epoch 480, content 97.134, style nan, time 18.0 sec\n",
      "epoch 520, content 97.134, style nan, time 17.9 sec\n",
      "epoch 560, content 97.134, style nan, time 17.3 sec\n",
      "epoch 600, content 97.134, style nan, time 17.4 sec\n",
      "change lr to  0.025\n",
      "epoch 640, content 97.134, style nan, time 17.2 sec\n",
      "epoch 680, content 97.134, style nan, time 18.4 sec\n",
      "epoch 720, content 97.134, style nan, time 18.4 sec\n",
      "epoch 760, content 97.134, style nan, time 18.7 sec\n",
      "epoch 800, content 97.134, style nan, time 18.3 sec\n",
      "epoch 840, content 97.134, style nan, time 17.9 sec\n",
      "epoch 880, content 97.134, style nan, time 17.2 sec\n",
      "change lr to  0.0125\n",
      "epoch 920, content 97.134, style nan, time 16.7 sec\n",
      "epoch 960, content 97.134, style nan, time 18.3 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc4AAAFeCAYAAAAMgP/zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZg38fG7fv7QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d4805f4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time\n",
    "from mxnet import autograd\n",
    "\n",
    "def train(params, max_epochs, lr, lr_decay_epoch=200):\n",
    "    tic = time()\n",
    "    trainer = gluon.Trainer(params, 'sgd', {'learning_rate': lr})\n",
    "    \n",
    "    for i in range(max_epochs):\n",
    "        x = params.get('generated_image')\n",
    "        with autograd.record():\n",
    "            content_py, style_py = extract_features(\n",
    "                x.data(), content_layers, style_layers)\n",
    "            content_L  = sum_loss(\n",
    "                content_loss, content_py, content_y, content_weights)\n",
    "            style_L = sum_loss(\n",
    "                style_loss, style_py, style_y, style_weights)\n",
    "            \n",
    "#             tv_L = tv_loss(x.data())\n",
    "            \n",
    "            loss = content_L + 500 * style_L\n",
    "            \n",
    "        loss.backward()\n",
    "        trainer.step(1)\n",
    "        \n",
    "        # add sync to avoid large mem usage\n",
    "        nd.waitall()\n",
    "\n",
    "        if i % 40 == 0:\n",
    "#             print('epoch %3d, content %.3f, style %.3f, tv %.3f, time %.1f sec' % (\n",
    "#                 i, content_L.asscalar(), style_L.asscalar(), tv_L.asscalar(), time()-tic))\n",
    "            print('epoch %3d, content %.3f, style %.3f, time %.1f sec' % (\n",
    "                i, content_L.asscalar(), style_L.asscalar(), time()-tic))\n",
    "            tic = time()\n",
    "\n",
    "        if i and i % lr_decay_epoch == 0:\n",
    "            lr *= 0.5\n",
    "            trainer.set_learning_rate(lr)\n",
    "            print('change lr to ', lr)        \n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "\n",
    "image_shape = (400,300)\n",
    "\n",
    "ctx = utils.try_gpu()\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "\n",
    "content_x, content_y = get_contents(image_shape)\n",
    "style_x, style_y = get_styles(image_shape)\n",
    "\n",
    "# plt.imshow(postprocess(content_x).asnumpy())\n",
    "# plt.show()\n",
    "# plt.imshow(postprocess(style_x).asnumpy())\n",
    "# plt.show()\n",
    "\n",
    "# x = mx.gluon.Parameter('generated_image', shape=(1, 3, 300, 400))\n",
    "# x.initialize(ctx=ctx)\n",
    "# x.set_data(content_x)\n",
    "\n",
    "# params = mx.gluon.ParameterDict()\n",
    "# params.update({'generated_image':x})\n",
    "# params.reset_ctx(ctx)\n",
    "\n",
    "param_file = 'results/saved_param_transfer_6_1_color2'\n",
    "params.load(param_file, ctx=ctx)\n",
    "\n",
    "learnt_params = train(params, max_epochs=2000, lr=0.005, lr_decay_epoch=2000)\n",
    "learnt_params.save('results/saved_param_transfer_6_1_color2')\n",
    "\n",
    "y = learnt_params.get('generated_image')\n",
    "\n",
    "plt.imshow(postprocess(y.data()).asnumpy())\n",
    "plt.show()\n",
    "plt.imsave('results/transfer_6_1_color2.png', postprocess(y.data()).asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
