{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 100\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mxnet import image\n",
    "style_img = image.imread('resources/style_6.jpg')\n",
    "content_img = image.imread('resources/content_1.jpg')\n",
    "\n",
    "from mxnet import nd\n",
    "\n",
    "rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def preprocess(img, image_shape):\n",
    "    img = image.imresize(img, *image_shape)\n",
    "    img = (img.astype('float32')/255 - rgb_mean) / rgb_std\n",
    "    return img.transpose((2,0,1)).expand_dims(axis=0)\n",
    "\n",
    "def postprocess(img):\n",
    "    img = img[0].as_in_context(rgb_std.context)\n",
    "    return (img.transpose((1,2,0))*rgb_std + rgb_mean).clip(0,1)\n",
    "\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "pretrained_net = models.vgg19(pretrained=True)\n",
    "swap_layer = 11\n",
    "\n",
    "def get_net(pretrained_net, swap_layer):\n",
    "    net = nn.HybridSequential()\n",
    "    for i in range(swap_layer + 1):\n",
    "        net.add(pretrained_net.features[i])\n",
    "    return net\n",
    "\n",
    "net = get_net(pretrained_net, swap_layer)\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from copy import deepcopy\n",
    "import math\n",
    "\n",
    "def extract_patches(features, patch_size, stride):\n",
    "    c, h, w = features.shape[1:]\n",
    "    n_h = math.floor((h - patch_size)/stride + 1)\n",
    "    n_w = math.floor((w - patch_size)/stride + 1)\n",
    "    patches = nd.zeros(shape=(n_h * n_w, c, patch_size, patch_size), ctx=ctx)\n",
    "    for i in range(n_h*n_w):\n",
    "        h = math.floor(i / n_w)\n",
    "        w = math.floor(i % n_w)\n",
    "        patches[i] = features[0, :, (h*stride):(h*stride + patch_size), (w*stride):(w*stride + patch_size)]\n",
    "    return patches\n",
    "\n",
    "def get_weight(target_patches, patch_size, patch_stride):\n",
    "#     convolution for computing cross correlation\n",
    "    n_patches, c, k_h, k_w = target_patches.shape\n",
    "    weight = deepcopy(target_patches)\n",
    "    kernel = (k_h, k_w)\n",
    "    num_filter = n_patches\n",
    "    stride = patch_stride\n",
    "#     normalize the patches to compute correlation\n",
    "    for i in range(n_patches):\n",
    "        norm = weight[i].norm()\n",
    "        if norm < 1e-6:\n",
    "            weight[i] = 0\n",
    "        else:\n",
    "            weight[i] = weight[i] * (1 / norm)\n",
    "            \n",
    "    return weight, kernel, stride, num_filter\n",
    "    \n",
    "\n",
    "image_shape = (200,150)\n",
    "patch_size = 5\n",
    "patch_stride = 5\n",
    "\n",
    "ctx = utils.try_gpu()\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "\n",
    "style_x = preprocess(style_img, image_shape).copyto(ctx)\n",
    "target_features = net(style_x)\n",
    "target_patches = extract_patches(target_features, patch_size, patch_stride)\n",
    "cc_weight, cc_kernel, cc_stride, cc_num_filter = get_weight(target_patches, patch_size, patch_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params, max_epochs, lr, lr_decay_epoch=200):\n",
    "    tic = time()\n",
    "    trainer = gluon.Trainer(params, 'adam', {'learning_rate': lr})\n",
    "    \n",
    "    for i in range(max_epochs):\n",
    "        x = params.get('content_img')\n",
    "        with autograd.record():\n",
    "            \n",
    "            content_features = net(x.data())\n",
    "            patches_L = patches_loss(content_features)\n",
    "#             tv_L = tv_loss(x.data())\n",
    "            loss = patches_L\n",
    "            \n",
    "        loss.backward()\n",
    "        trainer.step(1)\n",
    "        \n",
    "        # add sync to avoid large mem usage\n",
    "        nd.waitall()\n",
    "\n",
    "        if i % 40 == 0:\n",
    "            print('epoch %3d, patches %.3f, time %.1f sec' % (i, patches_L.asscalar(), time()-tic))\n",
    "            tic = time()\n",
    "\n",
    "        if i and i % lr_decay_epoch == 0:\n",
    "            lr *= 0.5\n",
    "            trainer.set_learning_rate(lr)\n",
    "            print('change lr to ', lr)        \n",
    "    \n",
    "    return params\n",
    "\n",
    "def tv_loss(yhat):\n",
    "    return 0.5*((yhat[:,:,1:,:] - yhat[:,:,:-1,:]).abs().mean() +\n",
    "                (yhat[:,:,:,1:] - yhat[:,:,:,:-1]).abs().mean())\n",
    "\n",
    "def patches_loss(content_features):\n",
    "    print(content_features.shape)\n",
    "    print(cc_weight.shape)\n",
    "    print(cc_num_filter)\n",
    "    c, h, w = content_features.shape[1:]\n",
    "    print(content_features.max())    \n",
    "    cc = nd.Convolution(data=content_features, weight=cc_weight, kernel=cc_weight.shape[2:], stride=cc_stride, num_filter=cc_num_filter, no_bias=True)\n",
    "    print(cc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 37, 50)\n",
      "(70, 256, 5, 5)\n",
      "70\n",
      "\n",
      "[ 84.35720825]\n",
      "<NDArray 1 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "content_x = preprocess(content_img, image_shape).copyto(ctx)\n",
    "\n",
    "x = mx.gluon.Parameter('content_img', shape=(1, 3, 150, 200))\n",
    "x.initialize(ctx=ctx)\n",
    "x.set_data(content_x)\n",
    "params = mx.gluon.ParameterDict()\n",
    "params.update({'content_img':x})\n",
    "\n",
    "# param_file = 'results/saved_param_transfer_6_1'\n",
    "# params.load(param_file)\n",
    "\n",
    "params.reset_ctx(ctx)\n",
    "\n",
    "content_features = net(x.data())\n",
    "patches_L = patches_loss(content_features)\n",
    "\n",
    "# learnt_params = train(params, max_epochs=1000, lr=0.001, lr_decay_epoch=1000)\n",
    "# learnt_params.save('results/saved_param_transfer_6_1')\n",
    "\n",
    "# y = learnt_params.get('generated_image')\n",
    "\n",
    "# plt.imshow(postprocess(y.data()).asnumpy())\n",
    "# plt.show()\n",
    "# plt.imsave('results/transfer_6_1.png', postprocess(y.data()).asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
